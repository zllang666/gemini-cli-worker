# Gemini CLI OpenAI Worker Environment Variables

# Required: OAuth2 credentials JSON from Gemini CLI authentication
# Get this by running `gemini auth` and copying the contents of ~/.gemini/oauth_creds.json
GCP_SERVICE_ACCOUNT={"access_token":"ya29.a0AS3H6Nx...","refresh_token":"1//09FtpJYpxOd...","scope":"https://www.googleapis.com/auth/cloud-platform ...","token_type":"Bearer","id_token":"eyJhbGciOiJSUzI1NiIs...","expiry_date":1750927763467}

# Optional: Google Cloud Project ID (auto-discovered if not set)
# GEMINI_PROJECT_ID=your-project-id

# Optional: API key for authentication (if not set, API is public)
# When set, clients must include "Authorization: Bearer <your-api-key>" header
# Example: sk-1234567890abcdef1234567890abcdef
OPENAI_API_KEY=sk-your-secret-api-key-here

# Optional: Enable fake thinking output for thinking models (set to "true" to enable)
# When enabled, models marked with thinking: true will generate synthetic reasoning text
# before providing their actual response, similar to OpenAI's o3 model behavior
ENABLE_FAKE_THINKING=true

# Optional: Enable real Gemini thinking output (set to "true" to enable)
# When enabled, requests with include_reasoning=true will use Gemini's native thinking
# This requires thinking-capable models and provides genuine reasoning from Gemini
ENABLE_REAL_THINKING=true

# Optional: Stream thinking as content with <thinking> tags (DeepSeek R1 style)
# When enabled along with either thinking mode, reasoning will be streamed as regular content
# wrapped in <thinking></thinking> tags instead of using the reasoning field
STREAM_THINKING_AS_CONTENT=true

# Optional: Auto switch from Pro to flash when you are getting rate-limited
ENABLE_AUTO_MODEL_SWITCHING=true